"""
Copy the DeBERTa ONNX model + label map to client/public/models and regenerate labelMap.ts.

Input:  models/saved_model/asl_deberta.onnx + label_map.json
Output: client/public/models/asl_deberta.onnx + label_map.json + labelMap.ts
"""

import json
import shutil
import sys
from pathlib import Path

from landmark_config import (
    KEPT_LANDMARKS, TO_AVG, TYPE_ARRAY, KEPT_FLAT,
    SEQ_LEN, N_LANDMARKS, NUM_CLASSES,
)

SCRIPT_DIR = Path(__file__).parent
PROJECT_DIR = SCRIPT_DIR.parent
MODEL_DIR = PROJECT_DIR / "models" / "saved_model"
OUTPUT_DIR = PROJECT_DIR.parent / "client" / "public" / "models"
LABEL_MAP_SRC = PROJECT_DIR / "data" / "processed" / "label_map.json"


def convert():
    onnx_src = MODEL_DIR / "asl_deberta.onnx"
    if not onnx_src.exists():
        print(f"ONNX model not found at {onnx_src}")
        print("Run export_deberta_onnx.py first.")
        sys.exit(1)

    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

    shutil.copy(onnx_src, OUTPUT_DIR / "asl_deberta.onnx")
    print(f"Copied asl_deberta.onnx to {OUTPUT_DIR}")

    # Copy label map
    label_map_json = None
    for src in [LABEL_MAP_SRC, MODEL_DIR / "label_map.json"]:
        if src.exists():
            shutil.copy(src, OUTPUT_DIR / "label_map.json")
            label_map_json = OUTPUT_DIR / "label_map.json"
            print(f"Copied label_map.json from {src}")
            break

    print("\nOutput files:")
    for f in sorted(OUTPUT_DIR.iterdir()):
        size_kb = f.stat().st_size / 1024
        print(f"  {f.name} ({size_kb:.1f} KB)")

    # Generate labelMap.ts
    if label_map_json and label_map_json.exists():
        with open(label_map_json) as f:
            label_map = json.load(f)

        max_idx = max(int(k) for k in label_map.keys())
        labels = [""] * (max_idx + 1)
        for idx_str, word in label_map.items():
            labels[int(idx_str)] = word

        ts_path = (PROJECT_DIR.parent / "client" / "src" / "features"
                   / "asl" / "models" / "labelMap.ts")

        lines = [
            "/**",
            " * ASL model constants and label map.",
            " * Auto-generated by convert_to_tfjs.py â€” do not edit manually.",
            " */",
            "",
            f"export const NUM_CLASSES = {NUM_CLASSES};",
            f"export const SEQ_LEN = {SEQ_LEN};",
            f"export const NUM_LANDMARKS = {N_LANDMARKS};",
            "export const NUM_FEATURES = 5; // [type, x, y, z, landmark_id]",
            "",
            "export const ASL_LABELS: string[] = [",
        ]
        for i, word in enumerate(labels):
            comma = "," if i < len(labels) - 1 else ""
            lines.append(f"  '{word}'{comma}")
        lines.append("];")
        lines.append("")

        # Landmark config (mirrored from Python landmark_config.py)
        lines.append("/** Holistic indices (from 543) for each kept landmark group */")
        lines.append("export const KEPT_LANDMARKS: number[][] = [")
        for group in KEPT_LANDMARKS:
            lines.append(f"  [{', '.join(str(x) for x in group)}],")
        lines.append("];")
        lines.append("")

        lines.append("/** Holistic indices to average into virtual landmarks */")
        lines.append("export const TO_AVG: number[][] = [")
        for group in TO_AVG:
            lines.append(f"  [{', '.join(str(x) for x in group)}],")
        lines.append("];")
        lines.append("")

        lines.append("/** Flat list of all 95 kept holistic indices */")
        lines.append(f"export const KEPT_FLAT: number[] = [{', '.join(str(x) for x in KEPT_FLAT)}];")
        lines.append("")

        lines.append("/** Type ID for each of the 100 landmarks (1=left hand, 2=right hand, 3=silhouette, 4=lips, 5=arms, 6=cheeks/averaged) */")
        lines.append(f"export const TYPE_ARRAY: number[] = [{', '.join(str(x) for x in TYPE_ARRAY)}];")
        lines.append("")

        ts_path.write_text("\n".join(lines))
        print(f"\nGenerated {ts_path}")


if __name__ == "__main__":
    convert()
