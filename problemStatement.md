# Beyond Binary — Hackathon Track | Women in Tech

## About Hackathon Track

The Hackathon track of Beyond Binary is designed for participants who are interested in building technical solutions and translating ideas into functional prototypes. This track places a strong emphasis on implementation, experimentation, and problem-solving through technology.

Participants will work in teams to design, develop, and demonstrate a working solution that addresses the given problem statement. Supported by technical workshops and mentorship from industry professionals, teams will iteratively refine their solutions and explore practical implementation approaches.

Teams will be required to showcase their solution through technical submissions and a final presentation, demonstrating both the functionality of their prototype and the rationale behind their design choices. The Hackathon track encourages technical creativity, robustness of implementation, and clear demonstration of solution viability.

---

## Problem Statement 1

### Introduction

Technology has transformed how we communicate, learn, and navigate the world, but its potential in supporting specially-abled individuals remains under-explored. Even when assistive tools exist, they often target only one group, for example, systems that rely on speech, text, or vision, leaving out people who cannot use that specific mode. As a result, many specially-abled individuals still face barriers in daily life, communication, learning, and independence. **How might we design an assistive solution that works across multiple abilities instead of relying on a single mode of interaction?**

Participants are expected to research user needs, define the problem clearly, and design an inclusive solution addressing multiple abilities.

### The Challenge

Individuals with special needs often face persistent barriers to communication, education, mobility, and daily independence due to limited access to inclusive technologies and support systems. These challenges are further intensified for people who rely on sign language, especially those using diverse sign language dialects, where existing solutions frequently fail to account for regional variations, non-standardized gestures, and contextual nuances. As a result, many individuals remain socially isolated, face difficulties accessing essential services, and experience reduced opportunities for learning, employment, and community participation.

Current assistive technologies often focus on single-modality solutions (e.g., speech-to-text, basic sign recognition, or simple navigation aids), which do not fully address the complex and multi-layered needs of users with disabilities. The fragmentation of these tools and the lack of multimodal integration limit their real-world effectiveness and scalability. To create truly meaningful accessibility, we need innovative solutions that combine multiple modalities, such as vision, audio, text, haptics, and AI, into cohesive systems that adapt to individual needs, support diverse sign language dialects, and enhance communication and independence in everyday life.

Addressing these interconnected barriers through multimodal, user-centered approaches is essential not only for improving accessibility and quality of life for individuals with special needs, but also for fostering inclusive communities, promoting equal opportunities, and enabling full participation in education, work, and society.

---

## Example Approach to the Solution — PS1

Teams may explore multimodal assistive solutions that integrate vision, audio, haptics, and AI to support people with diverse abilities. For example:

- A real-time sign language translation system that uses computer vision (e.g., MediaPipe) to recognize one or more sign language dialects, with audio output or tactile cues for people who are deaf-blind.

- An adaptive communication platform that combines speech-to-text, text-to-speech, and gesture-based input to enable interaction for people with different sensory or motor abilities.

- A context-aware assistance tool that gives simple, personalized feedback or guidance for daily tasks like reading labels, identifying objects, or sending alerts, through visual, audio, or haptic signals for people with sensory or motor impairments.

Solutions should demonstrate **inclusive design**, consider **regional sign variations** if relevant, and be **scalable** in concept, even if only prototyped for a hackathon.

---

## Judging Criteria — Problem Statement 1

### Impact & Relevance (25%)

- Evaluates how meaningfully the solution addresses a real accessibility challenge.
- Judges assess clarity and accuracy of the problem definition, evidence of research or engagement with underserved disability communities, depth of target-user understanding (including intersectional needs), and the potential scale of impact.
- Strong solutions address significant barriers, clearly identify who benefits and how, and demonstrate relevance beyond a niche use case.

### Multimodal Innovation & Implementation (30%)

- Assesses how effectively the solution integrates multiple interaction modes (e.g., visual, audio, haptics, gesture) to improve accessibility.
- Judges evaluate the quality of multimodal integration, originality of technical approach, and creativity in applying or extending existing technologies.
- Ease of implementation is critical — solutions should leverage APIs or packages thoughtfully, minimize setup complexity, and enable fast, practical deployment.

### Technical Execution (17%)

- Evaluates code quality, system architecture, and appropriateness of technical choices.
- High scores reflect clean, modular, well-documented implementations with suitable design patterns.
- Judges consider whether the chosen tech stack supports accessibility requirements such as low latency, privacy, offline use, and robustness, without over- or under-engineering.

### Usability & Accessibility (15%)

- Assesses whether the solution is genuinely usable by people with disabilities.
- Judges look for accessibility-by-design and universal design principles that consider sensory, motor, and cognitive needs.
- Strong entries provide intuitive user experiences, low learning curves, adaptability to user preferences, and avoid introducing new accessibility barriers.

### Completeness & Presentation (13%)

- Evaluates the clarity and professionalism of the demo and documentation.
- Judges assess whether the demo effectively showcases real user scenarios, allows interactive testing or real-time inference, and communicates value and limitations clearly.
- Documentation should include setup, usage, architecture, limitations, and future work to support reproducibility and adoption.